{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/eljan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/eljan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Orta ixtisas təhsili müəssisələrinin tələbələr...</td>\n",
       "      <td>psixologiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xoşbəxtlik və həyatın mənası IV Fəsil. Peşə et...</td>\n",
       "      <td>psixologiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu hal əsrədək davam etdi. Dünyanın mahiyyətin...</td>\n",
       "      <td>psixologiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Etika \" insanın sirlərinə, onun digər insanlar...</td>\n",
       "      <td>psixologiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O, \" ethosu \" \" insanların adət etdikləri yaşa...</td>\n",
       "      <td>psixologiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317539</th>\n",
       "      <td>Rus klassisizmi ayrı-ayrı layihələrdə lakin gü...</td>\n",
       "      <td>arxitektura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317540</th>\n",
       "      <td>Bir Onlar eynilə Edel, Qoslavski, Ploşko, Zivə...</td>\n",
       "      <td>arxitektura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317541</th>\n",
       "      <td>Azərbaycan memarlığında müxtəlif obyektlərində...</td>\n",
       "      <td>arxitektura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317542</th>\n",
       "      <td>Əgər İsmailiyyədə obraz möhtəşəmliyi müşahidə ...</td>\n",
       "      <td>arxitektura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317543</th>\n",
       "      <td>Lakin sənaye tikintisi, Azərbaycan iqtisadiyya...</td>\n",
       "      <td>arxitektura</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317544 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text       source\n",
       "0       Orta ixtisas təhsili müəssisələrinin tələbələr...  psixologiya\n",
       "1       Xoşbəxtlik və həyatın mənası IV Fəsil. Peşə et...  psixologiya\n",
       "2       Bu hal əsrədək davam etdi. Dünyanın mahiyyətin...  psixologiya\n",
       "3       Etika \" insanın sirlərinə, onun digər insanlar...  psixologiya\n",
       "4       O, \" ethosu \" \" insanların adət etdikləri yaşa...  psixologiya\n",
       "...                                                   ...          ...\n",
       "317539  Rus klassisizmi ayrı-ayrı layihələrdə lakin gü...  arxitektura\n",
       "317540  Bir Onlar eynilə Edel, Qoslavski, Ploşko, Zivə...  arxitektura\n",
       "317541  Azərbaycan memarlığında müxtəlif obyektlərində...  arxitektura\n",
       "317542  Əgər İsmailiyyədə obraz möhtəşəmliyi müşahidə ...  arxitektura\n",
       "317543  Lakin sənaye tikintisi, Azərbaycan iqtisadiyya...  arxitektura\n",
       "\n",
       "[317544 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('texts/chunks.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8407it [00:00, 29843.39it/s]     | 0/24 [00:00<?, ?it/s]\n",
      "141939it [00:06, 23257.98it/s]   | 1/24 [00:00<00:08,  2.74it/s]\n",
      "28002it [00:01, 26507.28it/s]    | 3/24 [00:07<01:00,  2.88s/it]\n",
      "138981it [00:05, 26702.92it/s]   | 4/24 [00:09<00:46,  2.33s/it]\n",
      "124266it [00:05, 24837.54it/s]   | 5/24 [00:15<01:10,  3.69s/it]\n",
      "53435it [00:02, 25593.56it/s]    | 6/24 [00:21<01:20,  4.47s/it]\n",
      "1252792it [00:48, 26029.09it/s]  | 7/24 [00:24<01:05,  3.88s/it]\n",
      "49459it [00:01, 26737.71it/s]    | 8/24 [01:24<05:39, 21.24s/it]\n",
      "2373082it [01:20, 29484.75it/s]  | 9/24 [01:26<03:51, 15.42s/it]\n",
      "34216it [00:01, 21430.69it/s]    | 10/24 [03:07<09:40, 41.45s/it]\n",
      "74519it [00:03, 24533.10it/s]    | 11/24 [03:09<06:22, 29.46s/it]\n",
      "1378157it [00:54, 25338.14it/s]  | 12/24 [03:12<04:20, 21.68s/it]\n",
      "33502it [00:01, 26077.84it/s]    | 13/24 [04:20<06:30, 35.47s/it]\n",
      "2547965it [02:12, 19267.29it/s]  | 14/24 [04:21<04:12, 25.27s/it]\n",
      "28059it [00:01, 26471.58it/s]▎   | 15/24 [07:07<10:08, 67.58s/it]\n",
      "8322it [00:00, 28525.13it/s]█▋   | 16/24 [07:09<06:21, 47.66s/it]\n",
      "87681it [00:03, 27997.52it/s]█   | 17/24 [07:09<03:54, 33.46s/it]\n",
      "20581it [00:00, 24130.77it/s]█▌  | 18/24 [07:13<02:27, 24.58s/it]\n",
      "22619it [00:00, 24707.14it/s]█▉  | 19/24 [07:14<01:27, 17.51s/it]\n",
      "136519it [00:05, 25982.61it/s]█▎ | 20/24 [07:15<00:50, 12.59s/it]\n",
      "102162it [00:04, 24294.48it/s]█▊ | 21/24 [07:22<00:32, 10.76s/it]\n",
      "81742it [00:02, 32783.66it/s]███▏| 22/24 [07:27<00:18,  9.07s/it]\n",
      "4832it [00:00, 25860.01it/s]████▌| 23/24 [07:30<00:07,  7.28s/it]\n",
      "Processing files: 100%|██████████| 24/24 [07:30<00:00, 18.77s/it]\n"
     ]
    }
   ],
   "source": [
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace new lines with spaces\n",
    "    cleaned_text = re.sub(r'\\n', ' ', text)\n",
    "    # Remove multiple spaces\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def chunk_text(text, max_words=1000, overlap=1):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    current_count = 0\n",
    "    current_text = []\n",
    "    splits = []\n",
    "    for i, sentence in tqdm(enumerate(sentences)):\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        if current_count + len(words) > max_words and current_text:\n",
    "            splits.append(\" \".join(current_text))\n",
    "            current_text = current_text[-overlap:]  # Overlap the last sentence(s)\n",
    "            current_count = sum(len(nltk.word_tokenize(s)) for s in current_text)\n",
    "        current_text.append(sentence)\n",
    "        current_count += len(words)\n",
    "    # Add the last split if it has content\n",
    "    if current_text:\n",
    "        splits.append(\" \".join(current_text))\n",
    "    return splits\n",
    "\n",
    "def process_file(file_path, chunk_size, overlap):\n",
    "    text = read_file(file_path)\n",
    "    cleaned_text = clean_text(text)\n",
    "    chunks = chunk_text(cleaned_text, chunk_size, overlap)\n",
    "    return chunks\n",
    "\n",
    "def process_directory(directory_path, chunk_size, overlap):\n",
    "    file_chunks = {}\n",
    "    for filename in tqdm(os.listdir(directory_path), desc=\"Processing files\"):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            chunks = process_file(file_path, chunk_size, overlap)\n",
    "            file_chunks[filename] = chunks\n",
    "    return file_chunks\n",
    "\n",
    "directory_path = 'texts'\n",
    "chunk_size = 512\n",
    "overlap = 1\n",
    "\n",
    "file_chunks = process_directory(directory_path, chunk_size, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317544, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(key, value) for key, values in file_chunks.items() for value in values]\n",
    "df = pd.DataFrame(data, columns=['source', 'text'])\n",
    "df = df[['text', 'source']]\n",
    "df['source'] = df['source'].apply(lambda x: x.split('.')[0])\n",
    "df.to_parquet('chunks.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash1 vs Hash2: 10\n",
      "Hash1 vs Hash3: 18\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "from simhash import Simhash\n",
    "\n",
    "def get_features(text):\n",
    "    # Simple word tokenization; consider more sophisticated methods for real applications\n",
    "    words = text.lower().split()\n",
    "    return words\n",
    "\n",
    "def compute_simhash(text):\n",
    "    features = get_features(text)\n",
    "    return Simhash(features)\n",
    "\n",
    "# Example texts\n",
    "text1 = \"This is a sample text for deduplication man.\"\n",
    "text2 = \"This is a sample text for deduplication.\"\n",
    "text3 = \"This is another example of a text that might be similar.\"\n",
    "text4 = \"Hello  man how are you doing\"\n",
    "\n",
    "# Compute SimHashes\n",
    "hash1 = compute_simhash(text1)\n",
    "hash2 = compute_simhash(text2)\n",
    "hash3 = compute_simhash(text3)\n",
    "hash4 = compute_simhash(text4)\n",
    "\n",
    "# Comparing hashes\n",
    "print(f\"Hash1 vs Hash2: {hash1.distance(hash2)}\")  # Lower score -> more similar\n",
    "print(f\"Hash1 vs Hash3: {hash1.distance(hash3)}\")\n",
    "print(f\"{hash1.distance(hash4)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polygraf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
