{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LlamaForCausalLM:\n\tsize mismatch for model.layers.0.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.0.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.1.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.1.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.2.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.2.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.3.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.3.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.4.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.4.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.5.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.5.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.6.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.6.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.7.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.7.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.8.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.8.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.9.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.9.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.10.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.10.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.11.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.11.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/teamspace/studios/this_studio/inference-v2.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://vscode-01hr094ac3zrzhexq9d2ye6wcb.studio.lightning.ai/teamspace/studios/this_studio/inference-v2.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM(\n\u001b[1;32m     <a href='vscode-notebook-cell://vscode-01hr094ac3zrzhexq9d2ye6wcb.studio.lightning.ai/teamspace/studios/this_studio/inference-v2.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     config\n\u001b[1;32m     <a href='vscode-notebook-cell://vscode-01hr094ac3zrzhexq9d2ye6wcb.studio.lightning.ai/teamspace/studios/this_studio/inference-v2.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://vscode-01hr094ac3zrzhexq9d2ye6wcb.studio.lightning.ai/teamspace/studios/this_studio/inference-v2.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m model\u001b[39m.\u001b[39msave_pretrained(\u001b[39m\"\u001b[39m\u001b[39mbbb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://vscode-01hr094ac3zrzhexq9d2ye6wcb.studio.lightning.ai/teamspace/studios/this_studio/inference-v2.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m model1 \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mbbb\u001b[39;49m\u001b[39m\"\u001b[39;49m, state_dict\u001b[39m=\u001b[39;49mstate_dict)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    560\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 561\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    565\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    566\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    567\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3494\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3495\u001b[0m     (\n\u001b[1;32m   3496\u001b[0m         model,\n\u001b[1;32m   3497\u001b[0m         missing_keys,\n\u001b[1;32m   3498\u001b[0m         unexpected_keys,\n\u001b[1;32m   3499\u001b[0m         mismatched_keys,\n\u001b[1;32m   3500\u001b[0m         offload_index,\n\u001b[1;32m   3501\u001b[0m         error_msgs,\n\u001b[0;32m-> 3502\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   3503\u001b[0m         model,\n\u001b[1;32m   3504\u001b[0m         state_dict,\n\u001b[1;32m   3505\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3506\u001b[0m         resolved_archive_file,\n\u001b[1;32m   3507\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3508\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   3509\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   3510\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   3511\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   3512\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   3513\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   3514\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   3515\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   3516\u001b[0m         hf_quantizer\u001b[39m=\u001b[39;49mhf_quantizer,\n\u001b[1;32m   3517\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   3518\u001b[0m     )\n\u001b[1;32m   3520\u001b[0m \u001b[39m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   3521\u001b[0m model\u001b[39m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/modeling_utils.py:3977\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3973\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msize mismatch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m error_msg:\n\u001b[1;32m   3974\u001b[0m         error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m   3975\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3976\u001b[0m         )\n\u001b[0;32m-> 3977\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00merror_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3979\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unexpected_keys) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3980\u001b[0m     archs \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39marchitectures \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39marchitectures\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LlamaForCausalLM:\n\tsize mismatch for model.layers.0.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.0.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.1.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.1.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.2.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.2.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.3.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.3.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.4.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.4.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.5.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.5.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.6.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.6.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.7.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.7.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.8.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.8.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.9.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.9.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.10.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.10.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.11.self_attn.k_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for model.layers.11.self_attn.v_proj.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "import json\n",
    "from transformers.models.llama.configuration_llama import LlamaConfig\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM\n",
    "\n",
    "state_dict = torch.load('/teamspace/studios/this_studio/checkpoints/lit-tiny-llama-162M-v2/converted_model.pth')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/teamspace/studios/this_studio/checkpoints/lit-tiny-llama-162M-v2\")\n",
    "config = LlamaConfig(\n",
    "    vocab_size=32000,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    hidden_size=768,\n",
    "    intermediate_size=3072,\n",
    "    num_query_value_heads=4,\n",
    "    max_position_embeddings=512,\n",
    ")\n",
    "\n",
    "model = LlamaForCausalLM(\n",
    "    config\n",
    ")\n",
    "model.save_pretrained(\"bbb\")\n",
    "model1 = AutoModelForCausalLM.from_pretrained(\"bbb\", state_dict=state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "# state_dict = torch.load('out/hf-tinyllama/converted_model.pth')\n",
    "state_dict = torch.load('/teamspace/studios/this_studio/checkpoints/lit-tiny-llama-162M-v2/converted_model.pth')\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\",\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    hidden_size=768,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    state_dict=state_dict,\n",
    ")\n",
    "model.save_pretrained(\"aaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "state_dict = torch.load('/teamspace/studios/this_studio/checkpoints/lit-tiny-llama-162M-v3/converted_model.pth')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"aaa\"\n",
    ", state_dict=state_dict\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/teamspace/studios/this_studio/checkpoints/lit-tiny-llama-162M-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_tensors = []\n",
    "for k, v in state_dict.items():\n",
    "    # print(k, end=' - ')\n",
    "    # assert v.equal(state_dict[k])\n",
    "    # print(\"equal\", end='\\n')\n",
    "    # print(k, v.shape)\n",
    "    # print(v, v.shape)\n",
    "    state_tensors.append(v)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tensors = []\n",
    "for k, v in model.named_parameters():\n",
    "    # print(k, end=' - ')\n",
    "    # assert v.equal(state_dict[k])\n",
    "    # print(\"equal\", end='\\n')\n",
    "    # print(v.shape)\n",
    "    # print(v, v.shape)\n",
    "    model_tensors.append(v)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32000, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([256, 768]) True\n",
      "torch.Size([768, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([3072, 768]) True\n",
      "torch.Size([768, 3072]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([768]) True\n",
      "torch.Size([32000, 768]) True\n"
     ]
    }
   ],
   "source": [
    "for mt in model_tensors:\n",
    "    are_close = False\n",
    "    for st in state_tensors:\n",
    "        try:\n",
    "            are_close = torch.allclose(mt, st.to(torch.float32))\n",
    "            if are_close:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    print(mt.shape, are_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> Azərbaycanın paytaxtı Bakı şəhəridir. Bakı şəhəri qədim tarixə və zəngin mədəniyyətə malik olan şəhərdir. Paytaxt Bakı şəhəri ilə yanaşı Azərbaycanın digər şəhərləri də qədim tarixə və zəngin mədəniyyətə malik olan şəhərlərdir. Paytaxt Bakı şəhəri və onun qəsəbələri qədim tarixə malik olan şəhərlərin sırasında xüsusi yer tutur. Bakı şəhərinin tarixi keçmişi haqqında müxtəlif mənbələrdə müxtəlif fikirlər mövcuddur. Məsələn, Azərbaycan tarixçisi Musa Kalankatlı Bakının qədim tarixə malik olduğunu qeyd edərək yazır: \"Şəhərin adı \"şəhərin paytaxtı\" deməkdir. Şəhərin adı \"şəhərin paytaxtı\" deməkdir. Şəhərin adı şəhərin adının mənası ilə yanaşı, həm də şəhərin tarixi keçmişini əks etdirir. Şəhərin adı şəhərin adının mənası ilə yanaşı, həm də şəhərin tarixi keçmişini əks etdirir. Şəhərin adı şəhərin adının mənası ilə yanaşı, həm də şəhərin tarixi keçmişini əks etdirir. Şəhərin adı şəhərin adının mənası ilə yanaşı, həm də şəhərin tarixi keçmişini əks etdirir. Şəhərin adı şəhərin adının mənası ilə yanaşı, həm də şəhərin tarixi keçmişini əks etdirir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının mənası \"şəhərin paytaxtı\" deməkdir. Şəhərin adının '"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Azərbaycanın paytaxtı Bakı şəhəridir\", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256)\n",
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s> Azərbaycanın paytaxtı Bakı şəhəridir. Bakı şəhərinin tarixi hissəsi olan İçərişəhərin ərazisində yerləşən bu şəhər Azərbaycanın ən qədim şəhərlərindən biridir. İçərişəhərin ərazisində yerləşən Qız qalası Azərbaycanın qədim tarixə malik şəhərlərindən biridir. İçərişəhərin ərazisində yerləşən Qız qalası XII əsrdə tikilmişdir. Qız qalası XII əsrdə Şirvanşahlar dövlətinin paytaxtı olmuşdur. Qız qalası Bakının mərkəzində yerləşən Qız qalasının yaxınlığında yerləşir. Qız qalası Bakının qədim tarixə malik olan qədim tikililərindən biridir. Qız qalası Bakının qədim tarixə malik olan qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının qədim tikililərindən biridir. Qız qalası Bakının '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v3\n",
    "inputs = tokenizer(\"Azərbaycanın paytaxtı Bakı şəhəridir\", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256)\n",
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri bütün dövrlərin görkəmli Azərbaycan yazıçıları tərəfindən yaxşı öyrənilmişdir. Bizim ədəbiyyatımız isə Nizamini Azərbaycan şairi kimi qiymətləndirir. Nizaminin əsərləri də çox böyük dəyərli və qiymətli ədəbiyyatımızdır. Burada Nizamiyə qədər olan insanların böyük ədəbiyyata, incəsənətə, tarixə xidmət etməsini göstərmək çox çətindir. Nizami bu böyük şairimizdir. Nizaminin yaratdığı bu böyük irsin dəyərini bilmək bizim üçün çox vacib məsələdir. Bu dahi Azərbaycan şairinin əsərlərində onun həyatı dərindən nəzərdən keçirilir. Dahi şairin ən böyük nailiyyəti Azərbaycan mədəniyyətidir. Nizaminin əsərləri o qədər böyük məna gətirir ki, onlar Azərbaycan mənəviyyatının ayrılmaz hissəsidir. Nizami Azərbaycan şairidir. Azərbaycanın poeziyası bir xalqın ruhunun və ruhunun təzahürüdür. Azərbaycan ədəbiyyatı elə bir xəzinədir ki, onu gələcək nəsillərə ötürmək üçün böyük səy göstər\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri \", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, temperature=1, do_sample=True)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri təkcə Azərbaycan dilində deyil, dünyanın bir çox ölkələrində yaxşı tərcümə olunub, nəşr olunub. Nizami Gəncəvi türk dilinin gözəl şairidir. O, türk dilində yazıb-yaradır. Onun əsərlərinin hamısı türk dilindədir. O, çox istedadlı bir şairdir. Onun əsərləri türkcəyə tərcümə ediləndən sonra dünyanın bir çox ölkələrində onun adı verilib, yüksək adlar alıbdır. O, öz əsərlərini çox gözəl ifa edibdir. Gəncənin ədəbi mühiti, mədəniyyəti və ümumiyyətlə Azərbaycanın çox zəngin ədəbiyyatı onun əsərlərindən ibarətdir. Ədəbiyyat və mədəniyyət sahəsində görülən çox böyük işlər onu yüksək qiymətləndirirəm. Ancaq mən çox təəssüf edirəm ki, Nizami Gəncə mühitini çox görmüşdür. Daxili İşlər naziri, polis general-mayoru Seyfulla Şirəliyev burada çox olmuş və o, Gəncədə çox ləyaqətlə xidmət etmişdir. Gəncə \n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "inputs = tokenizer(\"Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri \", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, temperature=1, do_sample=True)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri \"Xosrov və Şirin\"i, \"Dost və müasirim Nizami Gəncəvi\" (Azərbaycan şairləri Vəlixan), \"Böyük İsgəndərnamələr\", \"Böyük Azərbaycan şairi\" (Nizaminin poemaları, poemalar), \"Opsest\" (\"On hissədən\") mənzum hekayələri və şeirlərindən ibarətdir. Nizami Gəncəvi \"Xəmsə\"ni dünyanın bir çox ədəbiyyat dillərinə tərcümə edərək oxuculara çatdırıb. Habelə, dahi şair tərəfindən Nizami Gəncəvinin 600 illik yubileyi münasibətilə \"Nizami səyahətnamələri\", \"Nizaminin poeziya səyahətnamələri\", \"Nizami Gəncəvi - bir filosof şair kimi orta əsr Şərqinin poeziyasının zirvəsi\" kitablarını nəşr etdirib. Şeir kitabına Nizami Gəncəvi haqqında məqalələr, məktublar, xatirələr, əsərlərlə bağlı məlumatlar\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer('Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri \"Xosrov və Şirin\"', return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, temperature=1, do_sample=True)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri \"Xosrov və Şirin\"i, \"Qamzada\" poeması, \"Məxzənül-əsrar\" mənzum tarixi əsəri, \"İsgəndərnamə\" poeması onun adı ilə bağlıdır. Şirvanşahlar Sarayında yaşaması isə şair üçün böyük şərəf idi. 1522-ci ildə Şirvanı ikinci dəfə tərk edərkən şair orada böyük sarayın tikilməsini xahiş edib. 1530-cu ildə sarayda təmir işləri aparıldıqdan sonra şair özünü Bakıya dəvət edib. 1431-ci ildə Şirvanşah III Fəribürz Bakı xanının vəziri təyin edilib. 1615-ci ildə o, Gəncədə sarayın inşasına başlayanda burada işlər yekunlaşmaq üzrə idi. Şirvanşahların ölümündən sonra Şirvanın paytaxtı Gəncədən Bərdəyə köçməli olur. Burada da vəfat edib\n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "inputs = tokenizer('Nizami Gəncəvi Azərbaycanın dahi şairlərindən biridir. Onun əsərləri \"Xosrov və Şirin\"', return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, temperature=1, do_sample=True)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Fransanın paytaxtı haradır?- » Yenixeber.org - Oxu xəbərin olsun\n",
      "Fransanın paytaxtı haradır?- Fransa paytaxtıdır?- Tarix : 26-11-2020, 08:59\n",
      "Yenixeber.org: Fransa prezidenti Emmanuel Makron Fransanın paytaxtı Parisin meri Jan Fransua Löqarenin Fransa paytaxtının meri vəzifəsinə namizədliyini irəli sürüb. Fransa prezidenti Emmanuel Makron bu vəzifəyə namizədliyi irəli sürüləndə Fransa paytaxtının meri Jan Fransua Löqare bu vəzifəyə namizəd kimi irəli sürülüb. Fransa prezidenti Emmanuel Makron bu vəzifəyə namizədliyi irəli sürüləndə Fransa paytaxtının meri Jan Fransua Lö\n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"\"\"Fransanın paytaxtı haradır?\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.1)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> S: Azərbaycanın paytaxtı haradır?\n",
      "C: Azərbaycanın paytaxtı Bakı şəhəridir.\n",
      "S: Türkiyənin paytaxtı haradır?\n",
      "C: Türkiyənin paytaxtı Ankara şəhəridir.\n",
      "S: Fransanın paytaxtı haradır?\n",
      "Fransanın paytaxtı Paris şəhəridir. Parisin tarixi haqqında müxtəlif fikirlər mövcuddur. Bəziləri bu şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bu şəhərin tarixi haqqında müxtəlif fikirlər mövcuddur. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarixə malik olduğunu iddia edirlər. Bəziləri isə şəhərin qədim tarix\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"S: Azərbaycanın paytaxtı haradır?\n",
    "C: Azərbaycanın paytaxtı Bakı şəhəridir.\n",
    "S: Türkiyənin paytaxtı haradır?\n",
    "C: Türkiyənin paytaxtı Ankara şəhəridir.\n",
    "S: Fransanın paytaxtı haradır?\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.1)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> S: Azərbaycanın paytaxtı haradır?\n",
      "C: Azərbaycanın paytaxtı Bakı şəhəridir.\n",
      "S: Türkiyənin paytaxtı haradır?\n",
      "C: Türkiyənin paytaxtı Ankara şəhəridir.\n",
      "S: Fransanın paytaxtı haradır?\n",
      "Fransa Respublikasının paytaxtı Paris şəhəridir. Parisin tarixi haqqında ilk məlumat 1883-cü ildə fransız arxeoloqu Jak De Qoll tərəfindən verilmişdir (Jak De Qollun 1880-ci ildə Parisin tarixi haqqında ilk məlumatı 1880-ci ildə fransız arxeoloqu Jak De Qoll tərəfindən verilmişdir). Fransız arxeoloqu Jak De Qollun 1880-ci ildə Parisin tarixi haqqında ilk məlumatı 1880-ci ildə fransız arxeoloqu Jak De Qoll tərəfindən verilmişdir (Jak De Qollun 1880-ci ildə Parisin tarixi haqqında ilk məlumatı 1880-ci ildə fransız arxeoloqu \n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"\"\"S: Azərbaycanın paytaxtı haradır?\n",
    "C: Azərbaycanın paytaxtı Bakı şəhəridir.\n",
    "S: Türkiyənin paytaxtı haradır?\n",
    "C: Türkiyənin paytaxtı Ankara şəhəridir.\n",
    "S: Fransanın paytaxtı haradır?\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.1)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> S: Azərbaycanın paytaxtı haradır?-FOTO » Sportnet.az\n",
      "S: Azərbaycanın paytaxtı haradır?-FOTO\n",
      "Tarix: 21-11-2017, 21:52 Bölmə: Futbol / Topaz Premyer Liqası / Slider / Qırmızı\n",
      "Sportnet.az-ın məlumatına görə, Azərbaycan Premyer Liqasının XXII turunda \"Sabah\"la qarşılaşan \"Sabah\" ilk dəqiqələrdən rəqibinə ciddi müqavimət göstərib. İlk dəqiqələrdən rəqibin qapısı qarşısında təhlükəli vəziyyətlər yaradan \"Sabah\" rəqib qapısına yol tapıb. Oyunda hesabı açan tərəf \"Qarabağ\" olub. \"Qarabağ\" isə ilk dəqiqələrdən rəqibin qapısına yol tapıb. Oyunda hesab 1:1 olub. \"Qarabağ\" isə ilk dəqiqələrdən \n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"S: Azərbaycanın paytaxtı haradır?\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.1)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Salam, mən Azərbaycanın paytaxtı Bakıda doğulmuşam. Azərbaycanı çox sevirəm. Bakıda olmaqdan, burada qonaq olmaq fürsətindən danışarkən böyük məmnuniyyət hissi duyuram. Marketinq və dizayn sahəsində çox təcrübəyə malik bu istedadlı insanlar Azərbaycanın ən keyfiyyətli məhsulları üzrə keyfiyyətli və səmərəli işləməyi özlərinə şərəf hesab edirlər. Bakının gözəlliyini, gözəlliyini, həmçinin İçərişəhəri çox sevirəm. Bakı Şəhər İcra Hakimiyyəti tərəfindən təşkil olunan bu tədbirə böyük əhəmiyyət verdiyimə görə şəxsən Sizi məlumatlandırmaq istərdim. Bakı Şəhər Mədəniyyət və Turizm İdarəsinin təşkilatçılığı ilə şəhərin gözəlliyini yaxından və ustalıqla təbliğ etmək bacarığına malik olan çoxsaylı qurumlardan biri ilə (AZENCO Consulting GMB GROŞ) fəaliyyət göstəririk. Sizin rəhbərliyiniz ilə Bakı Beynəlxalq Forumunun keçirilməsi bizim ölkə üçün çox əhəmiyyətlidir. Bu Forum da Bakı sakinlərinə və \n"
     ]
    }
   ],
   "source": [
    "text = \"Salam, mən Azərbaycanın paytaxtı Bakıda doğulmuşam. \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=1)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Salam, mən Azərbaycanın paytaxtı Bakıda doğulmuşam. 1947-ci ildə orta məktəbi bitirdikdən sonra Azərbaycan Tibb Universitetində təhsil almaq istəyirəm. Azərbaycan Tibb Universitetində təhsil aldıqdan sonra 1949-cu ildə Azərbaycan Dövlət Tibb İnstitutuna daxil oldum. Ali universitet yataqxanasında yaşayan insanların həyatıyla maraqlandım. Burada bütün ixtisaslar üzrə təhsil alan tələbələr üçün universitet yataqxanasında şərait mükəmməl işləyirdi. 1956-cı ildə həmin yataqxanada yerləşən bu müasir kampusun tikintisi ilə tanış olduq. Burada təhsil aldığım müddətdə tədris etdiyim ixtisas ingilis dilində aparılırdı. Burada oxuyan tələbələr ana dilini də yaxşı bilmədiklərini qeyd etdiklərinə görə universitetlə birbaşa əlaqəm mövcuddur. Doktorantlarım Azərbaycan Tibb Universitetinin tədris planında, dərs vəsaitləri yazmaqla tanış olmuşdular. Bu təcrübə məni də çox ruhlandırdı. Bakalavr pilləsində olan aspirantlardan bu ali məktəbdə müəllim kimi işləməyə \n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"Salam, mən Azərbaycanın paytaxtı Bakıda doğulmuşam. \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=1)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Salam! Bakıda doğulmuş olmaq maraqlı bir təcrübə ola bilər, çünki bu şəhər zəngin tarixə, mədəniyyətə və gözəl mimariyə malikdir. Salam! Bu gün Bakıda anadan olmuş və burada böyümüş insanlar mənə Salam verirlər. Mən isə bunu çox arzulamışam və bütün arzularım gerçəkləşib. Bu günlərdə mən Azərbaycana qayıtdım və şəhərimiz haqqında məlumat aldım. Ümidvaram ki, bu, mənim Azərbaycana ilk səfərim olacaqdır. Bayramınız mübarək, əziz dostlar! Salam, xoş gəlmisiniz! Salam, əziz Salam! Salam! İlk əvvəl onu demək istəyirəm ki, mən Salam, xoş gəlmisiniz! Salam! İlk öncə mən Salam, mən və sizin qarşınızda çıxış etməkdən böyük şərəf hissi duyuram. Sizi bu gözəl şəhərdə salamlamaqdan böyük şərəf duyduğumu bildirmək istəyirik. Bu gözəl şəhər sizi çox gözəl qarşılayacaqdır və bizim bu görüşümüz Sizə çox xoş təsir bağışlayacaqdır. Mən Sizi bir daha ürəkdən salamlayıram. Salam, xoş gəlmisiniz! Salam! Bu gün mən Salam Salam, Bakı Salam. Bakı Salam, xoş gəlmisiniz! Salam! İlk növbədə mənə və mənim kimi Bakı sakinlərinə səmimi salamlar! İcazə verin, şəhərimizin sakinləri və qonaqları üçün ən xoş arzularımı ifadə edim və Sizin hamınıza xoş arzularımı bildirim. Salam və ən xoş arzular.</s>\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Salam! Bakıda doğulmuş olmaq maraqlı bir təcrübə ola bilər, çünki bu şəhər zəngin tarixə, mədəniyyətə və gözəl mimariyə malikdir. \"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Salam! Bakıda doğulmuş olmaq maraqlı bir təcrübə ola bilər, çünki bu şəhər zəngin tarixə, mədəniyyətə və gözəl mimariyə malikdir. Salam! İlk dəfə olaraq mən bunu sübut edə bildim, çünki bir çox ölkələrin vətəndaşıyam və bilirəm ki, dünyada kifayət qədər yaxşı dost, qardaş və dost insanlar var. Mən bilirəm ki, Azərbaycanda bir çox insanın həyatını yaxşılaşdıracaq bir çox imkanlar var və siz bunu bilirsiniz. Mən sizi dəvət edirəm ki, gəldiyiniz yerə gələsiniz və sizdə çox məmnun qaldığınızı, sizdə yaxşı dost və mehriban dostlar olduğunuzu hiss edəsiniz. Mən sizin ölkənizdə olmaq, onu ziyarət etmək və sizin ölkənizə gəlmək üçün bir neçə dəqiqədən sonra Azərbaycana gəldiyim üçün çox şadam.</s>\n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"\"\"Salam! Bakıda doğulmuş olmaq maraqlı bir təcrübə ola bilər, çünki bu şəhər zəngin tarixə, mədəniyyətə və gözəl mimariyə malikdir. \"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> İdmançılar gərək həmişə sağlıqlarına diqqət etsinlər. Təşəkkür edirəm cənab Prezident, çıxışımın sonunda qeyd etdiyiniz kimi, bu idman növü Azərbaycanda inkişaf edib. Sizin Sərəncamınızla Azərbaycanda Milli Olimpiya Komitəsi yaradılıb. Azərbaycan dünyada idman ölkəsi kimi tanınır. Federasiyanın fəaliyyəti nəticəsində idmançılarımız ölkəmizi layiqincə təmsil edirlər. Bu, bir daha onu göstərir ki, Azərbaycan idmançıları, idmançıları, məşqçiləri dünyada ölkəmizi ləyaqətlə təmsil edirlər və ölkəmizin inkişafını təmin edir. Azərbaycan idmançıları bu gün Avropa ölkələri arasında çox önəmli yerə malikdirlər. Siz idmanın bu növü ilə demək olar ki, məşğul olanda biz Avropa ölkələrinin, Olimpiya Oyunlarının, Yay Olimpiya Oyunlarının, digər beynəlxalq yarışların Azərbaycanda keçirilməsindən və burada görülən işlərə görə bizim idmançılarımıza, idmançılarımıza minnətdar oluruq. Onlar bizim dövlətimizin, ordumuzun yanındadır. İdmanda qazanılan uğurlarımızın təməlində xalqımızın ümummilli lideri Heydər Əliyevin və onun layiqli davamçısı Prezident İlham Əliyevin ölkəmizin inkişafına göstərdikləri diqqət və qayğı və onların fəaliyyəti dayanır. İdmanda qazanılan uğurlara görə biz idmançıları təltif edərkən onlara yüksək qiymət veririk. İdman və bədən tərbiyəsi sahəsində çalışan şəxslər isə yüksək ada layiqdirlər. İdmanda əldə olunan uğurlar idmançılarımızın qələbələrinə zəmin yaradır. İdmançılarımıza göstərilən dövlət qayğısı idman ictimaiyyətinin və idmançıların əməyinə verilən yüksək qiymətdir. İdmançılarımız da bu diqqət və qayğıya görə ölkə başçısı, prezident İlham Əliyevə minnətdarlıq bildirirlər. İdman və bədən tərbiyəsi bizim ən böyük sərvətimizdir. Biz idmanla məşğul olanda böyük məsuliyyət düşür. Azərbaycan idmançıları beynəlxalq yarışlarda çox yüksək nəticələr göstərirlər. Bunun səbəbi ondan ibarətdir ki, Azərbaycan idmançıları bu gün həm beynəlxalq aren\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"İdmançılar gərək həmişə sağlıqlarına diqqət etsinlər\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> İdmançılar gərək həmişə sağlıqlarına diqqət etsinlər. - İdmançıların qidalanmasından və əhval-ruhiyyəsindən razısınızmı? - Doymuşluq hissi ilə qidalanmalıyam. Çünki idmanla məşğul olmaq insanda çox acı hissi yaradır, eyni zamanda əsəb xəstəliyinə səbəb olur. - İdmana olan həvəsiniz nə ilə bağlıdır? - İdman üçün heç bir həvəsim yoxdur. Lakin idmana olan həvəsim daha da artıb. İdman mənim üçün çox dəyərlidir, çünki idmanla məşğul olduğuma görə özümü xoşbəxt hesab edirəm. İdman insanın ruhunu zənginləşdirir, onun əhval-ruhiyyəsini yaxşılaşdırır. İdman insana həm fiziki, həm də mənəvi güc verir. Mümkün qədər idmanla məşğul olmağa çalışıram. - İdmanla məşğulsunuz? - İdman mənim üçün həm fiziki, həm də mənəvi gücdür. İslamda idmana xüsusi əhəmiyyət verilir. Bu idman növünə İslamda geniş yer verilir. Çünki İslamda idmana böyük əhəmiyyət verilir. Ancaq idmana xüsusi əhəmiyyət verirlər. - İdmanla məşğul olan insanlarla münasibətiniz necədir? - İdmanla məşğul olmaq insanı gücləndirir. İdman insan üçün enerji mənbəyidir. İdman insanın daxili aləminin yaxşılaşmasına kömək edir. İdmanla məşğul olmaqla daxili enerji səviyyəsini sağlamlaşdırırıq. İnsan bədəninin müxtəlif yerlərində enerji yaradan və bədənin enerjisini artıran əzələlər var ki, bunlar da idmançılarda olan enerjini artırır. İdmana gələn insan ruhən sağlam olur. Ruhən sağlam olan insan ruhən sağlam qalır və daxili enerji ilə yanaşı bədəni enerji ilə təmin edir. İdmanla məşğul olan insan daha gözəl görünər. - İdmanla \n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"\"\"İdmançılar gərək həmişə sağlıqlarına diqqət etsinlər\"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> İdmançılar üçün sağlamlığa diqqət etmək, uğurlarının və uzunmüddətli karyeralarının əsas şərtlərindən biridir. Fiziki performansı yüksək səviyyədə saxlamaq üçün idmançılar daim sağlam qidalanma rejimini izləməli, düzgün istirahət etməli və mütəmadi olaraq fiziki müayinələrdən keçməlidirlər. Uşaqlar üçün sağlam həyat tərzi – idman\n",
      "Dünya praktikasında üzgüçülük – sağlam həyat tərzi hesab olunur. Bu idman növü uşaqlarda fiziki aktivliyin inkişafına təkan verir, fiziki aktivliyin yaranması və inkişafı üçün şərait yaradır. Uşaqlar və yeniyetmələr arasında üzgüçülüyün inkişafı üzrə ilk təlimlər keçirilir. Uşaqlara, yeniyetmələrə üzgüçülüklə yanaşı, sağlam həyat tərzi keçirmələri üçün şərait yaradılır. Uşaqlar və yeniyetmələr arasında üzgüçülüyün inkişafı üzrə ilk təlimlər 18-24 yaşlarda keçirilir. Bu təlimlər \"Üzgüçülük\" kateqoriyasında \"üzgüçülük\" adlanır. Üzgüçülük zamanı bədənin bütün hərəkətlərini (hərəkət, üzgüçülük, gəzinti) yerinə yetirmək və idmanla məşğuliyyətlər keçirilir. Üzgüçülüyün məqsədi orqanizmin sağlamlığını möhkəmləndirmək, fiziki sağlamlıq, zehni fəallığı yaxşılaşdırmaq, idmanla məşğul olanların fiziki hazırlığını yüksəltmək, idmançıların fiziki hazırlığını yüksəltməkdir. Üzgüçülüyün növləri\n",
      "Üzgüçülük (üzgüçülük) – bədənin müxtəlif nahiyyələrində üzgüçülük növlərindən biridir. Belə ki, bədənin müəyyən nahiyələrində bədənin müxtəlif nahiyyələrində üzmə növləri olur. Üzgüçülük zamanı bədən hərəkətlərinin koordinasiyasını yerinə yetirmək üçün bədənin müxtəlif nahiyyələrində olan əzələlər sıxılır, onların hərəkəti koordinasiya olunur, hərəkət zamanı üzmə zamanı əzələlər üzmə vərdişini itirirlər. Üz\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"İdmançılar üçün sağlamlığa diqqət etmək, uğurlarının və uzunmüddətli karyeralarının əsas şərtlərindən biridir. Fiziki performansı yüksək səviyyədə saxlamaq üçün idmançılar daim sağlam qidalanma rejimini izləməli, düzgün istirahət etməli və mütəmadi olaraq fiziki müayinələrdən keçməlidirlər. \"\"\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Türkiyənin prezidenti olan R.T.Ərdoğanın “erməni soyqırımı” iddiasıyla “soyqırım”dan imtina etdiyi də iddia olunur. xəbər verir ki, bu barədə informasiyanı “Anadolu” agentliyi yayıb. Qəzetin məlumatına görə, R.T.Ərdoğan “soyqırım” adı ilə məşhur olan 101 faizin “soyqırım” olduğunu iddia edir. “Millətimiz “soyqırım”a yox deyəcək gücə malikdir. Bu gücün sayəsində 1915-ci ildə Osmanlı İmperiyasında 150 min erməni olub. Bu gün də on minlərlə insan “soyqırım”a məruz qalıb”, – qəzet yazıb. \"Aftonbladet” qəzetinin məlumatına görə, bu barədə “Anadolu” agentliyi məlumat yayıb. Məlumata görə, Türkiyə hökuməti 1915-ci il hadisələrini soyqırımı kimi tanıyan ilk ölkə olub. Qəzetin yazdığına görə, \n"
     ]
    }
   ],
   "source": [
    "text = \"Türkiyənin prezidenti olan \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Türkiyənin prezidenti olan Rəcəb Tayyib Ərdoğanın son günlər verdiyi mesajlar, verdiyi bəyanatlar Türkiyənin xarici siyasətinin gücləndiyini göstərir. Türkiyə mediası Ərdoğanın \"Türkiyə NATO-ya üzv ola bilər, amma biz buna hazırıq\" deməsindən bəhs edib. Dünən isə Türkiyə prezidenti Rəcəb Tayyib Ərdoğan ABŞ-a səfər edib. Prezidentlər birgə mətbuat konfransı keçiriblər. Görüşdən sonra liderlər mətbuat konfransı keçiriblər. Türkiyə prezidenti bildirib ki, Türkiyə NATO üzrə müttəfiqlərini dəstəkləyir: \"NATO müttəfiqləri Türkiyəyə NATO-da yer tutmağa yardım etməlidirlər\". Ərdoğan qeyd edib ki, Türkiyə NATO-da yerini tutmaq arzusundadır. Ərdoğan NATO-nun üzvü olan ölkələrdən fərqli olaraq, Türkiyənin NATO ilə əlaqələrinin davam etdiyini vurğulayıb: \"NATO müttəfiqləri ilə birlikdə Türkiyənin NATO-da yer almasını istəyirik. Bu NATO müttəfiqləri NATO-da yer almaq üçün bizə dəstək olmalıdır\". ABŞ\n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"Türkiyənin prezidenti olan \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Azərbaycanın prezidenti olan ümummilli lider Heydər Əliyev 1993-cü ildə xalqın tələbi ilə hakimiyyətə qayıtdıqdan sonra ölkədə sabitliyə və inkişafa nail olmaqla yanaşı, demokratik inkişaf meyillərinin artmasına, vətəndaş cəmiyyətinin formalaşmasına və demokratik cəmiyyətin qurulmasına nail oldu. 1993- cü ildə Azərbaycanda dövlət çevrilişlərinin qarşısının alınması və xalqın təkidli tələbi ilə hakimiyyətə gələn ulu öndər Heydər Əliyev antimilli qüvvələrin törətdiyi qanunsuzluqların qarşısını aldı, ölkədə ictimai-siyasi sabitliyi bərpa etdi, iqtisadiyyata yeni təkan verdi, müstəqilliyimizi əbədi, dönməz etdi. 1995- ci ildə isə Heydər Əliyevin rəhbərliyi ilə ölkədə demokratik dövlət quruculuğu, vətəndaş cəmiyyətinin formalaşması istiqamətində kompleks tədbirlər həyata keçirildi, hakimiyyət bölgüsü prinsipinin və demokratik təsisatların əsası qoyuldu, vətəndaş cəmiyyətinin bərqərar olunması istiqamətində mühüm addımlar atıldı. Həmin dövrdə Azərbaycanda hüquqi dövlət və vətəndaş cəmiyyəti quruculuğunda böyük işlər görüldü. Bu \n"
     ]
    }
   ],
   "source": [
    "text = \"Azərbaycanın prezidenti olan \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Azərbaycanın prezidenti olan cənab İlham Əliyev erməni işğalçılarının Azərbaycan ərazisinin 20 faizini işğal etməsindən sonra öz doğma torpaqlarından didərgin düşmüş qaçqınlara dövlət qayğısını davamlı şəkildə artırır. Ölkə başçısının məcburi köçkünlərin yaşayış şəraitinin yaxşılaşdırılması istiqamətində həyata keçirdiyi tədbirlər bu kateqoriyadan olan insanlara qayğının tərkib hissəsidir. Bu xüsusda məcburi köçkünlərin problemlərinin həlli ilə bağlı həyata keçirilən tədbirlər sırasında Füzuli rayonunun Horadiz şəhərində və Bərdə rayonunda yeni yaşayış kompleksinin istifadəyə verilməsi xüsusi yer tutur və bu, bir daha onu göstərir ki, ölkəmizdə qaçqın və məcburi köçkünlərə göstərilən qayğı və diqqət göz qabağındadır. Təsadüfi deyildir ki, son illərdə Azərbaycan iqtisadiyyatının sürətli inkişafı sayəsində qaçqın və məcburi köçkünlərin sosial həyatında mühüm addımlar atılmışdır. Görülən işlərin məntiqi nəticəsi olaraq kompleksin tikintisinə başlanmışdır. Qaçqınların və məcburi köçkünlərin yaşayış şəraitinin yaxşılaşdırılması üçün bütün zəruri addımlar atılmışdır. Birinci vitse-prezident xanım Mehriban \n"
     ]
    }
   ],
   "source": [
    "# v3\n",
    "text = \"Azərbaycanın prezidenti olan \"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
    "print(tokenizer.decode(tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faa8e9c652449b5895899581d5d1195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/612M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/eljanmahammadli/AzLlama-152M/commit/6ca1588d41f7d559fbc5f88f90ab127b43f73768', commit_message='Upload LlamaForCausalLM', commit_description='', oid='6ca1588d41f7d559fbc5f88f90ab127b43f73768', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"AzLlama-152M\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152980224"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6c06c052d849da8abfa758ad4a9ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/eljanmahammadli/AzLlama-152M/commit/227fcce1b9d0ae8db6a513c184eb906416bbb464', commit_message='Upload tokenizer', commit_description='', oid='227fcce1b9d0ae8db6a513c184eb906416bbb464', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"AzLlama-152M\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('zzz/tokenizer_config.json',\n",
       " 'zzz/special_tokens_map.json',\n",
       " 'zzz/tokenizer.json')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('zzz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/generation/utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello, I am a newbie, and I am a newbie. I am a newbie'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPTNeoXForCausalLM, AutoTokenizer\n",
    "\n",
    "model = GPTNeoXForCausalLM.from_pretrained(\n",
    "  \"EleutherAI/pythia-70m-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-70m-deduped/step3000\",\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "  \"EleutherAI/pythia-70m-deduped\",\n",
    "  revision=\"step3000\",\n",
    "  cache_dir=\"./pythia-70m-deduped/step3000\",\n",
    ")\n",
    "\n",
    "inputs = tokenizer(\"Hello, I am\", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs)\n",
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the capital of France?\\n\\nThe French Revolution, in the early days of the French'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"What is the capital of France?\", return_tensors=\"pt\")\n",
    "tokens = model.generate(**inputs)\n",
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
