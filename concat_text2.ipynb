{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eljan/miniconda3/envs/kenlm_deepspeech/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration vrashad--books_dataset-181be1a7ccfd798d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/vrashad--books_dataset to /home/eljan/.cache/huggingface/datasets/vrashad___parquet/vrashad--books_dataset-181be1a7ccfd798d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 114M/114M [00:01<00:00, 62.6MB/s]\n",
      "Downloading data: 100%|██████████| 119M/119M [00:02<00:00, 50.5MB/s]\n",
      "Downloading data: 100%|██████████| 117M/117M [00:02<00:00, 50.1MB/s]\n",
      "Downloading data: 100%|██████████| 113M/113M [00:02<00:00, 51.2MB/s]\n",
      "Downloading data: 100%|██████████| 117M/117M [00:02<00:00, 56.4MB/s]\n",
      "Downloading data: 100%|██████████| 116M/116M [00:02<00:00, 57.1MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:17<00:00, 17.58s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 440.49it/s]\n",
      "                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/eljan/.cache/huggingface/datasets/vrashad___parquet/vrashad--books_dataset-181be1a7ccfd798d/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 86.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"vrashad/books_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02Uevkt5</td>\n",
       "      <td>Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...</td>\n",
       "      <td>Azərbaycan Respublikasının Prezidenti İlham Əl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02Uevkt5</td>\n",
       "      <td>Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...</td>\n",
       "      <td>Əsası ulu öndər Heydər Əliyev tərəfindən qoyul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02Uevkt5</td>\n",
       "      <td>Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...</td>\n",
       "      <td>Görülən yüksək səviyyəli işlərin, aparılan uğu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02Uevkt5</td>\n",
       "      <td>Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...</td>\n",
       "      <td>Burada Azərbaycanın ən ağrılı problemi olan Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02Uevkt5</td>\n",
       "      <td>Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...</td>\n",
       "      <td>Bu cildə, həmçinin müstəqil Azərbaycan dövlətç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807258</th>\n",
       "      <td>zZv9pT21</td>\n",
       "      <td>Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...</td>\n",
       "      <td>Rumıniyaya işgüzar səfər NATO-nun sammitində i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807259</th>\n",
       "      <td>zZv9pT21</td>\n",
       "      <td>Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...</td>\n",
       "      <td>Qazaxıstana işgüzar səfər Prezident İlham Əliy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807260</th>\n",
       "      <td>zZv9pT21</td>\n",
       "      <td>Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...</td>\n",
       "      <td>Türkiyəyə rəsmi səfər Prezident İlham Əliyev M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807261</th>\n",
       "      <td>zZv9pT21</td>\n",
       "      <td>Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...</td>\n",
       "      <td>Türkmənistana rəsmi səfər Moskvada Prezident İ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7807262</th>\n",
       "      <td>zZv9pT21</td>\n",
       "      <td>Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...</td>\n",
       "      <td>601Azərbaycan Respublikası Xarici İşlər Nazirl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7807263 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID                                           Metadata  \\\n",
       "0        02Uevkt5  Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...   \n",
       "1        02Uevkt5  Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...   \n",
       "2        02Uevkt5  Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...   \n",
       "3        02Uevkt5  Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...   \n",
       "4        02Uevkt5  Sərlövhə:İnkişaf - məqsədimizdir: birinci kita...   \n",
       "...           ...                                                ...   \n",
       "7807258  zZv9pT21  Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...   \n",
       "7807259  zZv9pT21  Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...   \n",
       "7807260  zZv9pT21  Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...   \n",
       "7807261  zZv9pT21  Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...   \n",
       "7807262  zZv9pT21  Sərlövhə:Azərbaycanın xarici siyasəti: sənədlə...   \n",
       "\n",
       "                                                  Sentence  \n",
       "0        Azərbaycan Respublikasının Prezidenti İlham Əl...  \n",
       "1        Əsası ulu öndər Heydər Əliyev tərəfindən qoyul...  \n",
       "2        Görülən yüksək səviyyəli işlərin, aparılan uğu...  \n",
       "3        Burada Azərbaycanın ən ağrılı problemi olan Da...  \n",
       "4        Bu cildə, həmçinin müstəqil Azərbaycan dövlətç...  \n",
       "...                                                    ...  \n",
       "7807258  Rumıniyaya işgüzar səfər NATO-nun sammitində i...  \n",
       "7807259  Qazaxıstana işgüzar səfər Prezident İlham Əliy...  \n",
       "7807260  Türkiyəyə rəsmi səfər Prezident İlham Əliyev M...  \n",
       "7807261  Türkmənistana rəsmi səfər Moskvada Prezident İ...  \n",
       "7807262  601Azərbaycan Respublikası Xarici İşlər Nazirl...  \n",
       "\n",
       "[7807263 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', ' Metadata', ' Sentence'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2764"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' Metadata'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naming(x):\n",
    "    try:\n",
    "        return x.split(\":\")[1]\n",
    "    except:\n",
    "        return \"error\"\n",
    "\n",
    "df['book_title'] = df[' Metadata'].apply(lambda x: naming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(' Metadata')\n",
    "\n",
    "idx = 0\n",
    "for book, group in tqdm(grouped):\n",
    "    # Concatenate all sentences into a single string for each book\n",
    "    full_text = ' '.join(group[' Sentence'])\n",
    "    \n",
    "    # Define the filename, using the book name. You might want to adjust this for valid filenames.\n",
    "    filename = f\"texts2/{idx}.txt\"\n",
    "    \n",
    "    # Write the concatenated text to a file\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(full_text)\n",
    "        \n",
    "    print(f\"Written '{filename}' with {len(full_text.split())} words.\")\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eljan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 2766/2766 [04:59<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  book  chunk_id                                               text\n",
      "0   53         1  Dekretdə deyilirdi: “1) Mülkədarların torpaq m...\n",
      "1   53         2  Məhz buna görə də Azərbaycanda torpaq məsələsi...\n",
      "2   53         3  Azərbaycanın bir hissəsini təşkil edən Naxçıva...\n",
      "3   53         4  Onlar əsas etibarı ilə ən yoxsul kəndliləri mu...\n",
      "4   53         5  Məsələn, Azərbaycanda istehsal edilən pambıq y...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Ensure NLTK is set up with the necessary components\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def chunk_text_into_blocks(text, max_words=400, overlap=True):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        words = sentence.split()\n",
    "        current_word_count += len(words)\n",
    "        current_chunk.append(sentence)\n",
    "        \n",
    "        # If the current word count exceeds the limit or it's the last sentence\n",
    "        if current_word_count >= max_words or i == len(sentences) - 1:\n",
    "            # Add the current chunk to the list of chunks\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [sentence] if overlap else []  # Start new chunk with overlap if enabled\n",
    "            current_word_count = len(words)  # Reset word count\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Assuming your text files are named after the books and stored in a directory named 'books'\n",
    "book_files = [f for f in os.listdir('texts2') if f.endswith('.txt')]\n",
    "data = []\n",
    "\n",
    "for book_file in tqdm(book_files):\n",
    "    with open(f\"texts2/{book_file}\", 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Chunk the book's text\n",
    "    chunks = chunk_text_into_blocks(text, 400)\n",
    "    \n",
    "    # Add chunks to the data list, along with the book name for identification\n",
    "    book_name = book_file.replace('.txt', '').replace('_', ' ')\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        data.append({'book': book_name, 'chunk_id': i + 1, 'text': chunk})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_chunks = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(df_chunks.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7807263, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350899, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>Dekretdə deyilirdi: “1) Mülkədarların torpaq m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>Məhz buna görə də Azərbaycanda torpaq məsələsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>Azərbaycanın bir hissəsini təşkil edən Naxçıva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>Onlar əsas etibarı ilə ən yoxsul kəndliləri mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>Məsələn, Azərbaycanda istehsal edilən pambıq y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350894</th>\n",
       "      <td>505</td>\n",
       "      <td>15</td>\n",
       "      <td>Respublika Elmi xibiisi ilə kənd kitabxanaları...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350895</th>\n",
       "      <td>505</td>\n",
       "      <td>16</td>\n",
       "      <td>Bu vəzifələrin yerinə yetirilməsində 1953-ciı ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350896</th>\n",
       "      <td>505</td>\n",
       "      <td>17</td>\n",
       "      <td>keyfiyyətcə yeni, mürəkkəb problemlər həll dil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350897</th>\n",
       "      <td>505</td>\n",
       "      <td>18</td>\n",
       "      <td>Kitabxana işi sahəsində əhaliyə olar. Xüsusi s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350898</th>\n",
       "      <td>505</td>\n",
       "      <td>19</td>\n",
       "      <td>hüquqi, demokratik, dünyəvi dövlətin yaran­ ic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350899 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book  chunk_id                                               text\n",
       "0        53         1  Dekretdə deyilirdi: “1) Mülkədarların torpaq m...\n",
       "1        53         2  Məhz buna görə də Azərbaycanda torpaq məsələsi...\n",
       "2        53         3  Azərbaycanın bir hissəsini təşkil edən Naxçıva...\n",
       "3        53         4  Onlar əsas etibarı ilə ən yoxsul kəndliləri mu...\n",
       "4        53         5  Məsələn, Azərbaycanda istehsal edilən pambıq y...\n",
       "...     ...       ...                                                ...\n",
       "350894  505        15  Respublika Elmi xibiisi ilə kənd kitabxanaları...\n",
       "350895  505        16  Bu vəzifələrin yerinə yetirilməsində 1953-ciı ...\n",
       "350896  505        17  keyfiyyətcə yeni, mürəkkəb problemlər həll dil...\n",
       "350897  505        18  Kitabxana işi sahəsində əhaliyə olar. Xüsusi s...\n",
       "350898  505        19  hüquqi, demokratik, dünyəvi dövlətin yaran­ ic...\n",
       "\n",
       "[350899 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sərlövhə:İnkişaf - məqsədimizdir: birinci kitab: avqust 2003-oktyabr 2003,Müəllif:Əliyev İlham Heydər oğlu,Nəşriyyat:Azərnəşr,Nəşr yeri:Bakı,Nəşr ili:2008,ISBN:978-9952-8100-7-3,Səhifə:424,Kateqoriya:Siyasət. Siyasi elmlər',\n",
       "       'Sərlövhə:Azərbaycanın və Dağıstanın böyük oğlu,Nəşriyyat:Göytürk,Nəşr yeri:Bakı,Nəşr ili:1998,Səhifə:254,Kateqoriya:Siyasət. Siyasi elmlər',\n",
       "       'Sərlövhə:Qeyri-su mühitində titrləmə,Müəllif:Rzayev Bayram Zülfüqar oğlu,Nəşriyyat:Elm,Nəşr yeri:Bakı,Nəşr ili:2003,ISBN:5-8066-1516-2,Səhifə:132,Kateqoriya:Ekologiya',\n",
       "       ...,\n",
       "       'Sərlövhə:Hind gözəlinin hekayəti,Müəllif:Nizami Gəncəvi,Nəşr yeri:Bakı,Nəşr ili:2019,Səhifə:8,Kateqoriya:Bədii ədəbiyyat',\n",
       "       'Sərlövhə:Qarabağ konflikti ABŞ-ın qlobal siyasəti kontekstində,Müəllif:İsmayılov Füzuli Cahangir oğlu,Nəşriyyat:Azərbaycan Milli Ensiklopediyası NPB,Nəşr yeri:Bakı,Nəşr ili:2001,ISBN:5-89600-313-7,Səhifə:152,Kateqoriya:Siyasət. Siyasi elmlər',\n",
       "       'Sərlövhə:Azərbaycanın xarici siyasəti: sənədlər məcmuəsi: 2008: I hissə,Nəşriyyat:GARISMA MMC,Nəşr yeri:Bakı,Nəşr ili:2009,ISBN:978-9952-8129-1-6,Səhifə:656,Kateqoriya:Siyasət. Siyasi elmlər'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' Metadata'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'Sərlövhə:Azərbaycanın xarici siyasəti: sənədlər məcmuəsi: 2008: I hissə,Nəşriyyat:GARISMA MMC,Nəşr yeri:Bakı,Nəşr ili:2009,ISBN:978-9952-8129-1-6,Səhifə:656,Kateqoriya:Siyasət. Siyasi elmlər'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Azərbaycanın xarici siyasəti'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.split(\":\")[1].split(\",\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks = df_chunks[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks.to_parquet('books.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eljan/miniconda3/envs/kenlm_deepspeech/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the parquet file\n",
    "df_chunks = pd.read_parquet('books.parquet')\n",
    "\n",
    "# convert pandas into datasets and push to the hub\n",
    "dataset = Dataset.from_pandas(df_chunks)\n",
    "dataset = DatasetDict({\"train\": dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 350899\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"eljanmahammadli/book-chunks-512-v2\", private=True, token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, concatenate_datasets, DatasetDict\n",
    "dataset1 = Dataset.from_dict({\"text\": [\"foo\", \"bar\"]})\n",
    "dataset2 = Dataset.from_dict({\"text\": [\"baz\", \"qux\"]})\n",
    "dataset = concatenate_datasets([dataset1, dataset2])\n",
    "dataset = DatasetDict({\"train\": dataset})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kenlm_deepspeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
